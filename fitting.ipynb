{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e286cd",
   "metadata": {},
   "source": [
    "# Fitting notebook.\n",
    "\n",
    "We now have all of the data preprocessing steps in order. Time to fiddle with the fitting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182ac043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from preprocessing_EventTypes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed3318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6c9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre-processing\n",
    "train_x, train_labels, valid_x, valid_labels, eventLabels  = fullProcessing( './train.csv', './train_labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "711488aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through questions 1 to 18 to train models for each question\n",
    "def fitModels(train_x, train_labels, valid_x, valid_labels):\n",
    "    # initialization\n",
    "    models = {}\n",
    "    train_eval = {}\n",
    "    valid_eval = {}\n",
    "    \n",
    "    # fitting\n",
    "    for q_no in range(1, 19):\n",
    "\n",
    "        # Select level group for the question based on the q_no.\n",
    "        if q_no <= 3:\n",
    "            grp = '0-4'\n",
    "        elif q_no <= 13:\n",
    "            grp = '5-12'\n",
    "        elif q_no <= 22:\n",
    "            grp = '13-22'\n",
    "        print(\"### q_no\", q_no, \"grp\", grp)\n",
    "\n",
    "        # Filter the rows in the datasets based on the selected q_no and level group.\n",
    "        train_df = train_x.loc[ train_x.index.isin([grp], level='level_group') ]\n",
    "        valid_df = valid_x.loc[ valid_x.index.isin([grp], level='level_group') ]\n",
    "\n",
    "        train_targets = train_labels.loc[train_labels.q == q_no].set_index('session')\n",
    "        valid_targets = valid_labels.loc[valid_labels.q == q_no].set_index('session')\n",
    "\n",
    "        # Model pipeline\n",
    "        pipe = Pipeline([('est', RandomForestClassifier())])\n",
    "\n",
    "        # Train\n",
    "        model = pipe.fit(train_df, train_targets['correct'])\n",
    "\n",
    "        # Store the model\n",
    "        models[f'{grp}_{q_no}'] = model\n",
    "\n",
    "        # Evaluate train and validation accuracy\n",
    "        train_eval[q_no] = accuracy_score(train_targets['correct'], model.predict(train_df) )\n",
    "        valid_eval[q_no] = accuracy_score(valid_targets['correct'], model.predict(valid_df) )\n",
    "    \n",
    "    return models, train_eval, valid_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43f6982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### q_no 1 grp 0-4\n",
      "### q_no 2 grp 0-4\n"
     ]
    }
   ],
   "source": [
    "models, train_eval, valid_eval = fitModels(train_x, train_labels, valid_x, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4723c73a",
   "metadata": {},
   "source": [
    "### Inspect Accuracy of Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee0a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, valid_acc in valid_eval.items():\n",
    "    train_acc = train_eval[name]\n",
    "    print(f\"question {name}: val accuracy {valid_acc:.4f}, train accuracy {train_acc:.4f}\")\n",
    "\n",
    "print(\"\\nAverage accuracy\", sum(evaluation_dict.values())/18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78450254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49bd50a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### q_no 1 grp 0-4\n",
      "frac predicted 0.7277309141068492\n",
      "targets 0.7277309141068492\n",
      "### q_no 2 grp 0-4\n",
      "frac predicted 0.9791500875378004\n",
      "targets 0.9791500875378004\n",
      "### q_no 3 grp 0-4\n",
      "frac predicted 0.9332590588360126\n",
      "targets 0.9332590588360126\n",
      "### q_no 4 grp 5-12\n",
      "frac predicted 0.7986630590482253\n",
      "targets 0.7986630590482253\n",
      "### q_no 5 grp 5-12\n",
      "frac predicted 0.5479866305904822\n",
      "targets 0.5479866305904822\n",
      "### q_no 6 grp 5-12\n",
      "frac predicted 0.7751074327550533\n",
      "targets 0.7751074327550533\n",
      "### q_no 7 grp 5-12\n",
      "frac predicted 0.73277096928219\n",
      "targets 0.73277096928219\n",
      "### q_no 8 grp 5-12\n",
      "frac predicted 0.6183882434081384\n",
      "targets 0.6183882434081384\n",
      "### q_no 9 grp 5-12\n",
      "frac predicted 0.7361133216616266\n",
      "targets 0.7361133216616266\n",
      "### q_no 10 grp 5-12\n",
      "frac predicted 0.5059154331794791\n",
      "targets 0.5059154331794791\n",
      "### q_no 11 grp 5-12\n",
      "frac predicted 0.6445965303199108\n",
      "targets 0.6445965303199108\n",
      "### q_no 12 grp 5-12\n",
      "frac predicted 0.8614250092843122\n",
      "targets 0.8614250092843122\n",
      "### q_no 13 grp 5-12\n",
      "frac predicted 0.27577059790970343\n",
      "targets 0.27577059790970343\n",
      "### q_no 14 grp 13-22\n",
      "frac predicted 0.7098519815374821\n",
      "targets 0.7098519815374821\n",
      "### q_no 15 grp 13-22\n",
      "frac predicted 0.4800254655419386\n",
      "targets 0.4800254655419386\n",
      "### q_no 16 grp 13-22\n",
      "frac predicted 0.7356358427502785\n",
      "targets 0.7356358427502785\n",
      "### q_no 17 grp 13-22\n",
      "frac predicted 0.6945196031619715\n",
      "targets 0.6945196031619715\n",
      "### q_no 18 grp 13-22\n",
      "frac predicted 0.9514563106796117\n",
      "targets 0.9514032574672396\n"
     ]
    }
   ],
   "source": [
    "for q_no in range(1, 19):\n",
    "\n",
    "    # Select level group for the question based on the q_no.\n",
    "    if q_no <= 3:\n",
    "        grp = '0-4'\n",
    "    elif q_no <= 13:\n",
    "        grp = '5-12'\n",
    "    elif q_no <= 22:\n",
    "        grp = '13-22'\n",
    "    print(\"### q_no\", q_no, \"grp\", grp)\n",
    "\n",
    "    # Filter the rows in the datasets based on the selected q_no and level group.\n",
    "    train_df = train_x.loc[ train_x.index.isin([grp], level='level_group') ]\n",
    "    valid_df = valid_x.loc[ valid_x.index.isin([grp], level='level_group') ]\n",
    "                                               \n",
    "    train_targets = train_labels.loc[train_labels.q == q_no].set_index('session')\n",
    "    valid_targets = valid_labels.loc[valid_labels.q == q_no].set_index('session')\n",
    "    \n",
    "    preds = models[grp+'_'+str(q_no)].predict(train_df)\n",
    "    \n",
    "    print('frac predicted', preds.sum() / len(preds) )\n",
    "    print( 'targets', train_targets.correct.sum() / len(train_targets))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33d54980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.tree._tree.Tree at 0x131170c00>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps['est'].estimators_[0].tree_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9d657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "343dafba",
   "metadata": {},
   "source": [
    "### Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jo_wilder\n",
    "env = jo_wilder.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2262a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference\n",
    "# https://www.kaggle.com/code/philculliton/basic-submission-demo\n",
    "# https://www.kaggle.com/code/cdeotte/random-forest-baseline-0-664/notebook\n",
    "\n",
    "limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n",
    "\n",
    "for (test, sample_submission) in iter_test:\n",
    "    test_df = feature_engineer(test)\n",
    "    grp = test_df.level_group.values[0]\n",
    "    a,b = limits[grp]\n",
    "    for t in range(a,b):\n",
    "        model = models[f'{grp}_{t}']\n",
    "        predictions = model.predict(test_df)\n",
    "        mask = sample_submission.session_id.str.contains(f'q{t}')\n",
    "        sample_submission.loc[mask,'correct'] = predictions.flatten()\n",
    "    \n",
    "    env.predict(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c09f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
