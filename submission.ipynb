{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e286cd",
   "metadata": {},
   "source": [
    "# Submission notebook\n",
    "\n",
    "Streamlined notebook for submission. Inherits from baselinemodel. Edit me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182ac043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aed3318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data proprocession functions\n",
    "\n",
    "eventVars = ['event_name', 'name', 'level', 'page', 'text', 'fqid', 'room_fqid', 'text_fqid' ]\n",
    "eventVars.sort()\n",
    "\n",
    "numericalVars = ['elapsed_time','room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y',\n",
    "        'hover_duration']\n",
    "\n",
    "def readData(fileLocation):\n",
    "    dtypes={\n",
    "        'elapsed_time':np.int32,\n",
    "        'event_name':'category',\n",
    "        'name':'category',\n",
    "        'level':'category',\n",
    "        'page':'category',\n",
    "        'room_coor_x':np.float32,\n",
    "        'room_coor_y':np.float32,\n",
    "        'screen_coor_x':np.float32,\n",
    "        'screen_coor_y':np.float32,\n",
    "        'hover_duration':np.float32,\n",
    "        'text':'category',\n",
    "        'fqid':'category',\n",
    "        'room_fqid':'category',\n",
    "        'text_fqid':'category',\n",
    "        'fullscreen':'category',\n",
    "        'hq':'category',\n",
    "        'music':'category',\n",
    "        'level_group':'category'}\n",
    "    data = pd.read_csv(fileLocation, dtype=dtypes)\n",
    "\n",
    "    for column in eventVars:\n",
    "        data[column] = data[column].cat.add_categories(['-1'])\n",
    "        data[column] = data[column].fillna('-1')\n",
    "    return data\n",
    "\n",
    "\n",
    "def readLabels(fileLocation):\n",
    "    \"\"\"Read the labels dataset\"\"\"\n",
    "    labels = pd.read_csv(fileLocation)\n",
    "    labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]))\n",
    "    labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]))\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def makeEventLabels(trainData):\n",
    "    \"\"\"Make a table containing the labels for any set of event values\"\"\"\n",
    "    eventGrouping = trainData.groupby(eventVars, observed=True)\n",
    "    eventLabels = pd.DataFrame( eventGrouping.size().index,\n",
    "                    columns=['event_profile'])\n",
    "\n",
    "    eventLabels['event_label'] = pd.DataFrame( \n",
    "            map(lambda i: 'e_'+ str(i), range(len(eventLabels))),\n",
    "            dtype='category')\n",
    "    return eventLabels\n",
    "\n",
    "\n",
    "def makeEventTable(data, eventLabels):\n",
    "    \"\"\"makes a table grouped by event types, session_id, and level_group\"\"\"\n",
    "    eventColumns = ['session_id', 'level_group', *eventVars]\n",
    "    eventTable = data[ eventColumns ]\n",
    "\n",
    "    eventTable = eventTable.groupby(eventColumns, observed=True).size().to_frame('counts')\n",
    "    eventTable = eventTable.reset_index(['session_id', 'level_group'])\n",
    "\n",
    "    eventDetails = pd.DataFrame( eventTable.index, columns=['event_profile'])\n",
    "    eventDetails = eventDetails.merge( eventLabels, on='event_profile', how='left' )\n",
    "\n",
    "    eventTable = eventTable.reset_index().drop(columns=eventVars)\n",
    "    eventTable['event_label'] = eventDetails['event_label']\n",
    "    \n",
    "\n",
    "    eventCounts = eventTable.pivot(index=['session_id', 'level_group'], columns='event_label', values='counts')\n",
    "    eventCounts = eventCounts.fillna(0)\n",
    "    return eventCounts\n",
    "\n",
    "\n",
    "def splitDataset(dataset, labels, train_ratio=0.80):\n",
    "    \"\"\"Random split of session_ids in the data.\n",
    "       The dataset should be indexed by ['session_id', 'level_group']\n",
    "    \"\"\"\n",
    "    \n",
    "    # `session_id` and `level_group` are the indices of our feature engineered dataset\n",
    "    if dataset.index.names != ['session_id', 'level_group']:\n",
    "        raise Exception( 'Data must be indexed by [session_id, level_group]' )\n",
    "    \n",
    "    sessionIds = dataset.index.get_level_values('session_id').unique()\n",
    "    trainIds, valIds = train_test_split(sessionIds, train_size=train_ratio )\n",
    "\n",
    "    trainData = dataset.loc[trainIds]\n",
    "    valData =  dataset.loc[valIds]\n",
    "    \n",
    "    trainLabels = labels[ labels.session.isin(trainIds) ]\n",
    "    valLabels = labels[ labels.session.isin(valIds) ]\n",
    "    \n",
    "    return trainData, trainLabels, valData, valLabels\n",
    "\n",
    "\n",
    "\n",
    "def fullProcessing(dataFile, labelFile):\n",
    "    trainData = readData(dataFile)\n",
    "    labelData = readLabels(labelFile)\n",
    "\n",
    "\n",
    "    eventLabels = makeEventLabels(trainData)\n",
    "    \n",
    "    eventTable = makeEventTable(trainData, eventLabels)\n",
    "    \n",
    "    # split datasets\n",
    "    trainData, trainLabels, valData, valLabels = splitDataset(eventTable, labelData, train_ratio=0.8)\n",
    "    \n",
    "    return trainData, trainLabels, valData, valLabels, eventLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee6c9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre-processing\n",
    "train_x, train_labels, valid_x, valid_labels, eventLabels  = fullProcessing( './train.csv', './train_labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03766d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "VAL_USER_LIST = valid_x.index.get_level_values('session_id').unique()\n",
    "prediction_df = pd.DataFrame(data=np.zeros(\n",
    "    (len(VAL_USER_LIST), 18)), index=VAL_USER_LIST)\n",
    "\n",
    "models = {}\n",
    "\n",
    "evaluation_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0810ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711488aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### q_no 1 grp 0-4\n",
      "### q_no 2 grp 0-4\n",
      "### q_no 3 grp 0-4\n",
      "### q_no 4 grp 5-12\n",
      "### q_no 5 grp 5-12\n",
      "### q_no 6 grp 5-12\n",
      "### q_no 7 grp 5-12\n",
      "### q_no 8 grp 5-12\n",
      "### q_no 9 grp 5-12\n",
      "### q_no 10 grp 5-12\n",
      "### q_no 11 grp 5-12\n",
      "### q_no 12 grp 5-12\n",
      "### q_no 13 grp 5-12\n",
      "### q_no 14 grp 13-22\n",
      "### q_no 15 grp 13-22\n",
      "### q_no 16 grp 13-22\n",
      "### q_no 17 grp 13-22\n",
      "### q_no 18 grp 13-22\n"
     ]
    }
   ],
   "source": [
    "# Iterate through questions 1 to 18 to train models for each question\n",
    "\n",
    "for q_no in range(1, 19):\n",
    "\n",
    "    # Select level group for the question based on the q_no.\n",
    "    if q_no <= 3:\n",
    "        grp = '0-4'\n",
    "    elif q_no <= 13:\n",
    "        grp = '5-12'\n",
    "    elif q_no <= 22:\n",
    "        grp = '13-22'\n",
    "    print(\"### q_no\", q_no, \"grp\", grp)\n",
    "\n",
    "    # Filter the rows in the datasets based on the selected q_no and level group.\n",
    "    train_df = train_x.loc[ train_x.index.isin([grp], level='level_group') ]\n",
    "    valid_df = valid_x.loc[ valid_x.index.isin([grp], level='level_group') ]\n",
    "    \n",
    "    train_targets = train_labels.loc[train_labels.q == q_no].set_index('session')\n",
    "    valid_targets = valid_labels.loc[valid_labels.q == q_no].set_index('session')\n",
    "\n",
    "    # Model pipeline\n",
    "    pipe = Pipeline([('est', RandomForestClassifier())])\n",
    "\n",
    "    # Train\n",
    "    model = pipe.fit(train_df, train_targets['correct'])\n",
    "\n",
    "    # Store the model\n",
    "    models[f'{grp}_{q_no}'] = model\n",
    "\n",
    "    # Evaluate the trained model on the validation dataset and store the\n",
    "    # evaluation accuracy in the `evaluation_dict`.\n",
    "    evaluation_dict[q_no] = accuracy_score(\n",
    "        valid_targets['correct'], model.predict(valid_df))\n",
    "\n",
    "    # Use the trained model to make predictions on the validation dataset and\n",
    "    # store the predicted values in the `prediction_df` dataframe.\n",
    "    predict = model.predict(valid_df)\n",
    "    prediction_df.loc[valid_targets.index, q_no-1] = predict.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43f6982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4723c73a",
   "metadata": {},
   "source": [
    "### Inspect Accuracy of Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee0a484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 1: accuracy 0.7263\n",
      "question 2: accuracy 0.9775\n",
      "question 3: accuracy 0.9370\n",
      "question 4: accuracy 0.7965\n",
      "question 5: accuracy 0.5237\n",
      "question 6: accuracy 0.7791\n",
      "question 7: accuracy 0.7490\n",
      "question 8: accuracy 0.6056\n",
      "question 9: accuracy 0.7369\n",
      "question 10: accuracy 0.4874\n",
      "question 11: accuracy 0.6378\n",
      "question 12: accuracy 0.8691\n",
      "question 13: accuracy 0.7273\n",
      "question 14: accuracy 0.6983\n",
      "question 15: accuracy 0.4923\n",
      "question 16: accuracy 0.7316\n",
      "question 17: accuracy 0.6582\n",
      "question 18: accuracy 0.9476\n",
      "\n",
      "Average accuracy 0.7267251337906973\n"
     ]
    }
   ],
   "source": [
    "for name, value in evaluation_dict.items():\n",
    "    print(f\"question {name}: accuracy {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage accuracy\", sum(evaluation_dict.values())/18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78450254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49bd50a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### q_no 1 grp 0-4\n",
      "frac predicted 0.7277309141068492\n",
      "targets 0.7277309141068492\n",
      "### q_no 2 grp 0-4\n",
      "frac predicted 0.9791500875378004\n",
      "targets 0.9791500875378004\n",
      "### q_no 3 grp 0-4\n",
      "frac predicted 0.9332590588360126\n",
      "targets 0.9332590588360126\n",
      "### q_no 4 grp 5-12\n",
      "frac predicted 0.7986630590482253\n",
      "targets 0.7986630590482253\n",
      "### q_no 5 grp 5-12\n",
      "frac predicted 0.5479866305904822\n",
      "targets 0.5479866305904822\n",
      "### q_no 6 grp 5-12\n",
      "frac predicted 0.7751074327550533\n",
      "targets 0.7751074327550533\n",
      "### q_no 7 grp 5-12\n",
      "frac predicted 0.73277096928219\n",
      "targets 0.73277096928219\n",
      "### q_no 8 grp 5-12\n",
      "frac predicted 0.6183882434081384\n",
      "targets 0.6183882434081384\n",
      "### q_no 9 grp 5-12\n",
      "frac predicted 0.7361133216616266\n",
      "targets 0.7361133216616266\n",
      "### q_no 10 grp 5-12\n",
      "frac predicted 0.5059154331794791\n",
      "targets 0.5059154331794791\n",
      "### q_no 11 grp 5-12\n",
      "frac predicted 0.6445965303199108\n",
      "targets 0.6445965303199108\n",
      "### q_no 12 grp 5-12\n",
      "frac predicted 0.8614250092843122\n",
      "targets 0.8614250092843122\n",
      "### q_no 13 grp 5-12\n",
      "frac predicted 0.27577059790970343\n",
      "targets 0.27577059790970343\n",
      "### q_no 14 grp 13-22\n",
      "frac predicted 0.7098519815374821\n",
      "targets 0.7098519815374821\n",
      "### q_no 15 grp 13-22\n",
      "frac predicted 0.4800254655419386\n",
      "targets 0.4800254655419386\n",
      "### q_no 16 grp 13-22\n",
      "frac predicted 0.7356358427502785\n",
      "targets 0.7356358427502785\n",
      "### q_no 17 grp 13-22\n",
      "frac predicted 0.6945196031619715\n",
      "targets 0.6945196031619715\n",
      "### q_no 18 grp 13-22\n",
      "frac predicted 0.9514563106796117\n",
      "targets 0.9514032574672396\n"
     ]
    }
   ],
   "source": [
    "for q_no in range(1, 19):\n",
    "\n",
    "    # Select level group for the question based on the q_no.\n",
    "    if q_no <= 3:\n",
    "        grp = '0-4'\n",
    "    elif q_no <= 13:\n",
    "        grp = '5-12'\n",
    "    elif q_no <= 22:\n",
    "        grp = '13-22'\n",
    "    print(\"### q_no\", q_no, \"grp\", grp)\n",
    "\n",
    "    # Filter the rows in the datasets based on the selected q_no and level group.\n",
    "    train_df = train_x.loc[ train_x.index.isin([grp], level='level_group') ]\n",
    "    valid_df = valid_x.loc[ valid_x.index.isin([grp], level='level_group') ]\n",
    "                                               \n",
    "    train_targets = train_labels.loc[train_labels.q == q_no].set_index('session')\n",
    "    valid_targets = valid_labels.loc[valid_labels.q == q_no].set_index('session')\n",
    "    \n",
    "    preds = models[grp+'_'+str(q_no)].predict(train_df)\n",
    "    \n",
    "    print('frac predicted', preds.sum() / len(preds) )\n",
    "    print( 'targets', train_targets.correct.sum() / len(train_targets))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33d54980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.tree._tree.Tree at 0x131170c00>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps['est'].estimators_[0].tree_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9d657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "343dafba",
   "metadata": {},
   "source": [
    "### Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jo_wilder\n",
    "env = jo_wilder.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2262a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference\n",
    "# https://www.kaggle.com/code/philculliton/basic-submission-demo\n",
    "# https://www.kaggle.com/code/cdeotte/random-forest-baseline-0-664/notebook\n",
    "\n",
    "limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n",
    "\n",
    "for (test, sample_submission) in iter_test:\n",
    "    test_df = feature_engineer(test)\n",
    "    grp = test_df.level_group.values[0]\n",
    "    a,b = limits[grp]\n",
    "    for t in range(a,b):\n",
    "        model = models[f'{grp}_{t}']\n",
    "        predictions = model.predict(test_df)\n",
    "        mask = sample_submission.session_id.str.contains(f'q{t}')\n",
    "        sample_submission.loc[mask,'correct'] = predictions.flatten()\n",
    "    \n",
    "    env.predict(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c09f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
